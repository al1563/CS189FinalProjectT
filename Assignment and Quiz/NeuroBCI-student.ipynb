{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NeuroBCI-student.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOkk6QW1o7Yv764tFdVOPyI"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"8Ram8qve2q33"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import os \n","%matplotlib inline\n","import seaborn as sns"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qXaPfZGO_4j8"},"source":["This is an image from Yu et al. (2011) IEEE Circuits and Systems that gives us a good visualization of the approach on spike detection to spike classification via dimensionality reduction.\n","![](https://www.researchgate.net/profile/Xiangyu_Li4/publication/260619153/figure/fig1/AS:339519564992512@1457959180390/Hebbian-eigenfilter-based-spike-sorting-algorithm.png)\n","\n","Below, we will be working on simlated spiking data to start with. The simulated data that we will be working with is described in depth in this paper: https://www2.le.ac.uk/departments/engineering/research/bioengineering/neuroengineering-lab/Publications/martinezJNM09.pdf\n","\n","_Martinez J, Pedreira C, Ison MJ, Quian Quiroga R. Realistic simulation of extracellular recordings. J Neurosci Methods. 2009 Nov 15;184(2):285-93. doi: 10.1016/j.jneumeth.2009.08.017. Epub 2009 Aug 22. PMID: 19703490._\n","\n","**The general workflow**\n","1. First, we need to preprocess the raw voltage recordings from ECoG or EEG (most likely, you will do spike sorting with ECoG as it will give the best spiking signal). This include filtering the frequencies and removing noise from the signal.\n","2. Next, with a cleaned signal, we need to detect peaks that represent neuronal spiking. Various algorithms have been described (in the figure above, NEO refers to nonlinear energy operator, a method of using energy to detect peaks). In the below code, we will use the spiking peaks that have already been given to us with the data. \n","Usually, after a peak detection step, the waveforms of the peaks are acquired by obtaining the signal around the peak, and then aligning the waveforms so that the peak appear in the middle (this is called peak alignment). \n","3. After waveform extraction, the peaks are represented in a d dimensional space that represents the signal around the time of the peak. This is where we want to be able to perform unsupervised clustering on the various waveforms. \n","Usually, a dimensionality reduction algorithm is applied, such as PCA, to represent the waveforms in a lower dimensional space. After that, K-means clustering or other unsupervised clustering algorithms are implemented in order to perform waveform classification. \n","With classification complete, we have a general idea of a neuron's behavior based upon the shape of the peak.\n","4. After classification, we can then look at other metrics of a neuron's behavior. Such as spike trains or frequency of excitation. We can examine how these signals change with certain tasks such as controlling a cursor on a computer. We can also examine how these signals are dysfunctional in disease like epilepsy. This is the basis of how brain computer interface (BCI) works, and how spike sorting comes into play. \n","\n","Here is a whole article on more details of spike sorting: http://www.scholarpedia.org/article/Spike_sorting"]},{"cell_type":"markdown","metadata":{"id":"klPL4lWHNcdM"},"source":["# Spike Sorting on Simulated Data"]},{"cell_type":"code","metadata":{"id":"lB5ZUjI4cPDE"},"source":["import scipy.io\n","import scipy.cluster"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ed5Jv_IcPii"},"source":["# download data\n","#!wget https://www2.le.ac.uk/departments/engineering/research/bioengineering/neuroengineering-lab/simulations/simulation-1.mat\n","!wget https://www2.le.ac.uk/departments/engineering/research/bioengineering/neuroengineering-lab/simulations/simulation-2.mat\n","# !wget https://www2.le.ac.uk/departments/engineering/research/bioengineering/neuroengineering-lab/simulations/simulation-3.mat\n","# !wget https://www2.le.ac.uk/departments/engineering/research/bioengineering/neuroengineering-lab/simulations/simulation-4.mat\n","# !wget https://www2.le.ac.uk/departments/engineering/research/bioengineering/neuroengineering-lab/simulations/simulation-5.mat"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yj8q5yW6O9Bf"},"source":["# extract signals and class\n","sim1 = {k:v for k,v in scipy.io.loadmat('simulation-2').items()}\n","signal= np.squeeze(sim1[\"data\"])\n","\n","spikeclass = sim1[\"spike_class\"][0][0][0]\n","spiketimes = np.squeeze(sim1[\"spike_times\"][0][0])\n","\n","print('Number of Spikes in each Class:')\n","for i, c in zip([0,1,2],np.bincount(spikeclass)):\n","  print(i, ':', c)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sAZB4_C6Wgvl"},"source":["The signals are 2 minute recordings, with a sampling rate of 24kHz. \n","There are 2 single unit class of neurons that we want to classify, mixed in with 1 multiunit class. The detection threshold is 24mV."]},{"cell_type":"code","metadata":{"id":"qkkkct_FIXR6"},"source":["# Visualize the signal\n","fs = 24000.0 # 24kHz sampling\n","plt.figure(figsize = (20,10))\n","seconds = np.arange(signal.shape[0])/fs\n","plt.plot(seconds, signal, label = 'signal')\n","plt.scatter(spiketimes/fs, np.ones(spiketimes.shape)*-100, c = 'r', s = 2, label = 'spiking')\n","plt.axhline(24, linestyle =':', c = 'g', label = 'detection threshold'); plt.legend(); \n","plt.title('Extracellular Recordings of Neurons'); plt.xlim([1,5]); \n","plt.xlabel('Time (s)'); plt.ylabel('Voltage (uA)')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9adwtfDVXDCC"},"source":["Let's go through an example of preprocessing and peak detection"]},{"cell_type":"code","metadata":{"id":"AhPkwV9zTpyT"},"source":["from scipy.signal import butter, lfilter\n","\n","def butter_bandpass(lowcut, highcut, fs, order=5):\n","    nyq = 0.5 * fs\n","    low = lowcut / nyq\n","    high = highcut / nyq\n","    b, a = butter(order, [low, high], btype='band')\n","    return b, a\n","def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n","    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n","    y = lfilter(b, a, data)\n","    return y\n","fs = 24000.0 # sampling frequency\n","lowcut = 30.0 # low frequency cutoff\n","highcut = 3000.0 # high frequency cutoff\n","\n","plt.figure(figsize = (20,10))\n","plt.plot(signal, label = 'noisy signal', alpha = .7)\n","# filter the signal\n","signalfilt = butter_bandpass_filter(signal, lowcut, highcut, fs, order=6)\n","plt.plot(signalfilt, label='Filtered signal', alpha = .7)\n","plt.axhline(24, linestyle =':', c = 'g', label = 'detection threshold');\n","plt.axis('tight'); plt.legend(loc='upper left')\n","plt.xlim([0,10000]); plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DWJEWzh9W-g7"},"source":["# An example of peak detection\n","from scipy.signal import find_peaks, peak_prominences\n","thres = 24\n","\n","pks = find_peaks(signalfilt, height = thres, distance = 60)[0]\n","plt.figure(figsize = (20,10))\n","plt.plot(signalfilt, label = 'signal')\n","plt.scatter(pks, signalfilt[pks], c = 'r', label = 'detected peaks')\n","plt.scatter(spiketimes, np.ones(spiketimes.shape)*-100, c = 'c', s = 5, label = 'given spike times')\n","plt.xlim([100,100000]); plt.legend(); plt.title('Detected Peaks')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O7AgW2NaWzUX"},"source":["# acquire waveforms from detected peaks\n","waveforms = list()\n","leftlim = 30\n","rightlim = 30\n","for p in pks:\n","  if p < leftlim:\n","    continue;\n","  if (len(signalfilt) - p) < rightlim: \n","    continue;\n","  waveforms.append(signalfilt[p-leftlim:p+rightlim])\n","\n","## plot the waveforms to visualize the data you will be working with\n","## CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"febGhwaWZHU5"},"source":["# Let's get the waveforms given to us, as they have already been assigned classes"]},{"cell_type":"code","metadata":{"id":"1bTcq5obY1Zx"},"source":["waveforms = list()\n","leftlim = 20\n","rightlim = 50\n","\n","plt.figure(); plt.title('pre-aligned');\n","for p in spiketimes:\n","  testwave = signalfilt[p-2:p+70]\n","  pk = find_peaks(testwave)[0]\n","  plt.plot(testwave)\n","  pk = pk[np.argmax(testwave[pk])]\n","  waveforms.append(signalfilt[p+pk-leftlim:p+pk+rightlim])\n","waveforms = np.vstack(waveforms)\n","plt.show();  plt.figure(); \n","plt.plot(waveforms.T); \n","plt.title('Spike Waveforms: Aligned');"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nw6LlI3Xba0V"},"source":["# Now plot each of the classes, remember the class to visualize. \n","# Spike classes are in spikeclass and there are 3 classes (2 corresponding to individual neurons, one class a mix of multiple neurons)\n","waveforms_df = pd.DataFrame(waveforms)\n","waveforms_df['class'] = spikeclass\n","\n","## CODE HERE\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RS-2YPoqYu4F"},"source":["# Dimensionality reduction and clustering."]},{"cell_type":"code","metadata":{"id":"bhHYmPbCeT-t"},"source":["# First, split our waveforms into training and test data, you can use the train_test_split function from sklearn\n","# recall your training data waveforms are in waveforms, and your labels are in spikeclass\n","from sklearn.model_selection import train_test_split\n","\n","## CODE HERE\n","X_train, X_test, y_train, y_test = \n","\n","## END CODE \n","\n","num_train, dims = X_train.shape\n","num_test, _ = X_test.shape\n","num_classes = 3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lz7iEYwUi18O"},"source":["## Implement the function project_data\n","def project_data(data, proj_basis, mean = None, plot = False, labels = None, s = 5, c = None):\n","  \"\"\" Projects the data (adjusted by the mean) onto proj_basis into basis vectors \n","    data is of shape N x d\n","    proj_basis is of shape k x d\n","    mean is of shape d x 1 \"\"\"\n","  if mean is not None:\n","    data = data - mean\n","\n","  ## CODE HERE\n","\n","  ## END CODE\n","\n","  if plot:\n","    if labels is not None:\n","\n","      for i, l in enumerate(np.unique(labels)):\n","        if c is not None: plt.scatter(proj_data[labels == l,0], proj_data[labels == l ,1], label = \"class: \" + str(l), s = s, c = c)\n","        else: plt.scatter(proj_data[labels == l,0], proj_data[labels == l ,1], label = \"class: \" + str(l), s = s)\n","        plt.legend();\n","    else: \n","      if c is None: plt.scatter(proj_data[:,0],proj_data[:,1], s = s)\n","      else:  plt.scatter(proj_data[:,0],proj_data[:,1], s = s, c = c)\n","\n","  return proj_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ETXl42ZphIMo"},"source":["# project to 2 random coordinated\n","coord = np.random.rand(2, dims);\n","plt.figure(figsize = (7,5))\n","project_data(X_train, coord, mean = X_train.mean(axis=0), plot = True, labels = y_train);\n","plt.title('Random Projections')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uz5haoKxfTBI"},"source":["def train_PCA(data, n_components):\n","  \"\"\" data is Nxd, n_components is number of basis you want to reduce the dimensions to \n","  Note: make sure you subtract the mean before you perform svd\n","  return both the new basis and the mean\"\"\"\n","\n","  ### CODE HERE\n","\n","\n","  ### CODE END\n","  return basis, mean"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qM8QMs_YfS-h"},"source":["## TRAIN YOUR PCA\n","## CODE HERE\n","\n","## CODE END\n","plt.figure(figsize = (6,5))\n","plt.plot(nmean, linewidth = 5); plt.title('Mean Spike'); plt.show();\n","\n","## Plot the basis vectors\n","## CODE HERE\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jKfzIT2ndsIn"},"source":["plt.figure(figsize = (7,5))\n","proj_train = project_data(X_train, nbasis, mean = nmean, plot = True, labels = y_train);\n","plt.title('First 2 Basis Projection (Training)')\n","\n","plt.figure(figsize = (7,5))\n","proj_test = project_data(X_test, nbasis, mean = nmean, plot = True, labels = y_test);\n","plt.title('First 2 Basis Projection (Testing)')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tMgLsZFU588_"},"source":["from mpl_toolkits.mplot3d import Axes3D\n","\n","fig=plt.figure(figsize=(10,7))\n","ax = fig.add_subplot(111, projection='3d')\n","for i in np.arange(num_classes):\n","  Axes3D.scatter(ax, proj_train[y_train==i,0],proj_train[y_train==i,1],proj_train[y_train==i,2], alpha = .4)\n","plt.title('Training')\n","\n","fig=plt.figure(figsize=(10,7))\n","ax = fig.add_subplot(111, projection='3d')\n","for i in np.arange(num_classes):\n","  Axes3D.scatter(ax, proj_test[y_test==i,0],proj_test[y_test==i,1],proj_test[y_test==i,2], alpha = .4)\n","plt.title('Testing')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DiF1FAvY5S4Z"},"source":[" Compare with sklearn PCA implementation\n"]},{"cell_type":"code","metadata":{"id":"P8_exGABbkGD"},"source":["from sklearn.decomposition import PCA\n","pca = PCA(n_components=2)\n","X_trans = pca.fit_transform(X_train)\n","plt.figure(figsize = (7,5))\n","for i in np.arange(num_classes):\n","  plt.scatter(X_trans[y_train==i,0], X_trans[y_train==i,1], s = 5)\n","plt.title('Training Projection')\n","\n","plt.show();\n","\n","X_trans = pca.transform(X_test)\n","plt.figure(figsize = (7,5))\n","for i in np.arange(num_classes):\n","  plt.scatter(X_trans[y_test==i,0], X_trans[y_test==i,1], s = 5)\n","plt.title('Test Projection')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4wUh4xA1cM4u"},"source":["When we do actual recordings, we do not know the underlying classes of the waveforms - so we will need to perform unsupervised clustering in order to determine the different groups of waveforms. We see that we have three distinct clusters in PCA. As such, we will implement an algorithm called k-means from sklearn which will perform unsupervised clustering in order to extract the cluster labels for you. The algorithm uses an iterative approach to identify centroids of k groups. You will learn more about this algorithm through a machine learning course."]},{"cell_type":"code","metadata":{"id":"4xbIsZmGcMS5"},"source":["from sklearn.cluster import KMeans\n","kmeans = KMeans(n_clusters=3, random_state=42).fit(proj_train)\n","kmean_classes = kmeans.labels_\n","\n","fig=plt.figure(figsize=(10,7))\n","for i in np.arange(num_classes):\n","  plt.scatter(proj_train[kmean_classes==i,0],proj_train[kmean_classes==i,1], s = 5)\n","plt.title('K-Means Clusters')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s8Xwu7pihxlS"},"source":["## Now that we identify the 3 clusters, find the centroids.\n","\n","centroid = list()\n","for i in np.arange(3):\n","## CODE HERE\n","\n","\n","## CODE END\n","\n","fig=plt.figure(figsize=(10,7))\n","for i in np.arange(num_classes):\n","  plt.scatter(proj_train[kmean_classes==i,0],proj_train[kmean_classes==i,1], s = 5)\n","  plt.scatter(centroid[i][0], centroid[i][1], c = 'k', s = 70)\n","plt.title('K-Means Clusters with Centroids')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"buI7phsvcEQa"},"source":["# compute distances to each centroid\n","# iterate through each centroid and compute distance for each waveform\n","def classify_neuron(proj_waveform, centroid):\n","  nclass = len(centroid)\n","  distances = np.empty((proj_waveform.shape[0], nclass))\n","  ## CODE HERE\n","\n","\n","\n","  ## CODE END\n","  return np.argmin(distances, axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8xeM25HVprGo"},"source":["proj_test = project_data(X_test, nbasis, nmean)\n","test_classes = classify_neuron(proj_test, centroid)\n","\n","fig=plt.figure(figsize=(10,7))\n","for i in np.arange(num_classes):\n","  plt.scatter(proj_test[test_classes==i,0],proj_test[test_classes==i,1], s = 5)\n","  plt.scatter(centroid[i][0], centroid[i][1], c = 'k', s = 70)\n","plt.title('Classification of Test Neurons with Centroids')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xt886xi1tVOA"},"source":["# Count number of times single neurons fire in the full signal\n","proj_all = project_data(waveforms, nbasis, nmean)\n","classes_all = classify_neuron(proj_all, centroid)\n","\n","num_firings = np.unique(classes_all, return_counts = True)[1]\n","\n","print('Neuron 1 fired {} times'.format(num_firings[1]))\n","print('Neuron 2 fired {} times'.format(num_firings[2]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8xfcoyZ_ykNY"},"source":["# look at interspike intervals for each cluster!\n","for i in np.arange(num_classes):\n","  times = spiketimes[classes_all == i]\n","  time_diff = np.diff(times)/fs\n","  plt.figure(figsize = (15,3))\n","  plt.hist(time_diff, bins = 50); plt.ylabel('Inter-spike interval (seconds)')\n","  plt.xlim([0, 2]); plt.title('Neuron cluster '+ str(i)); plt.ylabel('Counts')\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4uKtllkUz3za"},"source":[""],"execution_count":null,"outputs":[]}]}